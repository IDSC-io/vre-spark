{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Explorer Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import networkx as nx\n",
    "import bokeh\n",
    "from holoviews import opts\n",
    "\n",
    "hv.extension('bokeh')\n",
    "\n",
    "os.chdir(\"../../\")\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "# sys.path.append('../')\n",
    "# os.chdir(\"../\")\n",
    "print(os.getcwd())\n",
    "\n",
    "import configparser\n",
    "import logging\n",
    "import pathlib\n",
    "import networkx as nx\n",
    "\n",
    "from src.features.dataloader import DataLoader\n",
    "from src.models.networkx_graph import SurfaceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s - %(levelname)s: %(message)s', level=logging.INFO,\n",
    "                    datefmt='%d.%m.%Y %H:%M:%S')\n",
    "\n",
    "logging.info(\"Initiating data_loader\") # initiate data loader\n",
    "\n",
    "\n",
    "loader = DataLoader(hdfs_pipe=False) # load all data\n",
    "dataset = loader.prepare_dataset(\n",
    "        load_patients=True,\n",
    "        load_cases=True,\n",
    "        load_stays=True,\n",
    "        load_appointments=True,\n",
    "        load_devices=True,\n",
    "        load_care_data=False, # enable if visualization works with other data\n",
    "        load_employees=True,\n",
    "        load_rooms=True,\n",
    "        load_buildings=True,\n",
    "        load_partners=False,\n",
    "        load_medications=False,\n",
    "        load_risks=False,\n",
    "        load_chop_codes=False,\n",
    "        load_surgeries=False,\n",
    "        load_icd_codes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Dashboard Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for building_id, building in dataset[\"buildings\"].items():\n",
    "    records.append(building.get_record())\n",
    "    \n",
    "waveware_buildings_df = pd.DataFrame.from_records(records)\n",
    "waveware_buildings_df.drop(columns=[\"SAP Building Abbreviation 1\"], inplace=True)\n",
    "waveware_buildings_df = waveware_buildings_df.drop_duplicates(subset=[\"WW Building ID\"])\n",
    "waveware_buildings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show building data we have directly from Waveware\n",
    "# base_folder = \"./data/raw/model_data/\"\n",
    "# waveware_buildings_df = pd.read_csv(base_folder + \"Waveware_Auszug Gebaeudeinformation Stand 03.12.2020.csv\", encoding=\"ISO-8859-1\", dtype=str)\n",
    "\n",
    "# waveware_buildings_df = waveware_buildings_df.drop([\"Standort\", \"Parzellennummer\", \"Zonenplan\", \"Denkmalpflege\", \"Anlage-ID\", \"Bemerkung\", \"Eigentümer (SAP)\", \"Vermietung (SAP)\", \"Portfolio (SAP)\", \"Baujahr\", \"Gebäudetyp\", \"GVB-Nummer\", \"Amtlicher Wert\", \"Gebäudeversicherungswert\", \"Gebäudezustand\", \"Technologiestand HLKSE\", \"Techn. Ausb.standard\", \"Zustand Technik\", \"Klimatisierung\", \"Aufzug\", \"Gebäudezustand Bem.\", \"Status\"], axis=1)\n",
    "# waveware_buildings_df.columns = [\"Waveware Building Full ID\", \"Building Code\", \"Waveware Building ID\", \"Building abbreviation\", \"Building Common Name\", \"Street\", \"Zip Code\", \"Location\", \"SAP-Anlage Nr.\"]\n",
    "# waveware_buildings_df.drop([\"Zip Code\", \"Location\",\"SAP-Anlage Nr.\", \"Building Code\"], axis=1, inplace=True)\n",
    "# waveware_buildings_df = waveware_buildings_df[waveware_buildings_df[\"Building Common Name\"] != \"Grundstück Inselareal\"]\n",
    "\n",
    "# waveware_buildings_df = waveware_buildings_df[~pd.isna(waveware_buildings_df[\"Building abbreviation\"])]\n",
    "# waveware_buildings_df.sort_values(by=[\"Building abbreviation\"], inplace=True)\n",
    "# # waveware_buildings_df.set_index(\"Waveware Building ID\", inplace=True)\n",
    "# waveware_buildings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # augment building data with building coordinates\n",
    "# # TODO: Move this to dataset improvement\n",
    "# import requests\n",
    "\n",
    "# def get_long_lat(street_string):\n",
    "#     response = requests.get(f\"https://nominatim.openstreetmap.org/search?q={street_string.replace(' ', '+')}+Bern&format=json\")\n",
    "#     types = []\n",
    "#     for loc in response.json():\n",
    "#         types.append(loc[\"type\"] + \": \" + loc[\"display_name\"][:15])\n",
    "#         if loc[\"type\"] in [\"hospital\", \"childcare\", \"clinic\"]:\n",
    "#             id_string = loc[\"type\"] + \": \" + loc[\"display_name\"][:15]\n",
    "#             long_lat = (loc[\"lon\"], loc[\"lat\"])\n",
    "#             return pd.Series({'Type': id_string, 'Long/Lat': long_lat})\n",
    "        \n",
    "#     id_string = response.json()[0][\"type\"] + \": \" + response.json()[0][\"display_name\"][:15]\n",
    "#     long_lat = (response.json()[0][\"lon\"], response.json()[0][\"lat\"])\n",
    "#     return pd.Series({'Type': id_string, 'Long/Lat': long_lat})\n",
    "\n",
    "\n",
    "# waveware_buildings_coords_df = pd.concat([waveware_buildings_df, waveware_buildings_df[\"Street\"].apply(lambda s: get_long_lat(s))], axis=1)\n",
    "# waveware_buildings_coords_df[\"Longitude\"] = waveware_buildings_coords_df[\"Long/Lat\"].apply(lambda ll: float(ll[0]))\n",
    "# waveware_buildings_coords_df[\"Latitude\"] = waveware_buildings_coords_df[\"Long/Lat\"].apply(lambda ll: float(ll[1]))\n",
    "# waveware_buildings_coords_df.drop([\"Long/Lat\"], axis=1, inplace=True)\n",
    "# waveware_buildings_coords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waveware_buildings_coords_df[\"Waveware Building ID\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    waveware_buildings_df, geometry=gpd.points_from_xy(waveware_buildings_df.Longitude, waveware_buildings_df.Latitude))\n",
    "gdf.set_crs(epsg=4326, inplace=True)\n",
    "gdf = gdf.to_crs(epsg=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['coords'] = gdf['geometry'].apply(lambda x: x.representative_point().coords[:])\n",
    "gdf['coords_x'], gdf['coords_y'] = [coords[0][0] for coords in gdf['coords']], [coords[0][1] for coords in gdf['coords']]\n",
    "\n",
    "building_coordinates = list(gdf.apply(lambda row: [row[\"WW Building ID\"], (row[\"coords_x\"], row[\"coords_y\"])], axis=1))\n",
    "building_coordinates = {item[0]:item[1] for item in building_coordinates}\n",
    "# for row in gdf.iteritems():\n",
    "#     building_coordinates[row[\"WW Building ID\"]] = (row[\"coords_x\"], row[\"coords_y\"])\n",
    "\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Dashboard Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "import random\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "import xarray as xr\n",
    "import hvplot.pandas  # noqa\n",
    "import hvplot.xarray  # noqa\n",
    "hv.extension('bokeh')\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side Pane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"buildings\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(dataset[\"patients\"].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build timeline\n",
    "from holoviews.plotting.links import RangeToolLink\n",
    "\n",
    "base_folder = \"./data/interim/model_data/\"\n",
    "vre_screening_df = pd.read_csv(base_folder + \"VRE_SCREENING_DATA.csv\", encoding=\"ISO-8859-1\", parse_dates=[\"Birth Date\", \"Measurement Date\"], dtype=\"str\")\n",
    "\n",
    "# do some preprocessing\n",
    "vre_screening_df[\"Patient ID\"] = vre_screening_df[\"Patient ID\"].apply(lambda patient_id: str(patient_id).zfill(11))\n",
    "df = vre_screening_df\n",
    "vre_screening_df[\"Measurement Date d64\"] = vre_screening_df[\"Measurement Date\"].astype(\"datetime64\")\n",
    "df = vre_screening_df.loc[vre_screening_df[\"Result\"] != \"nn\"]\n",
    "df[\"Year\"] = df[\"Measurement Date d64\"].dt.year\n",
    "df[\"Week\"] = df[\"Measurement Date d64\"].dt.week\n",
    "x = pd.DataFrame(df[[\"Measurement Date d64\"]].groupby([df[\"Year\"], df[\"Week\"]]).count())\n",
    "x.columns = [\"Count\"]\n",
    "x = x.reset_index()\n",
    "x[\"Week\"] = x[\"Week\"].astype(\"int32\").astype(\"str\")\n",
    "x[\"Year\"] = x[\"Year\"].astype(\"int32\").astype(\"str\")\n",
    "x[\"Year/Week\"] = x[\"Year\"] + \"/\" + x[\"Week\"] + \"1\"\n",
    "x[\"Measurement Week\"] = x[\"Year/Week\"].apply(lambda x: pd.to_datetime(x, format='%Y/%W%w'))\n",
    "x[[\"Measurement Week\", \"Count\"]]\n",
    "\n",
    "timeline_curve = hv.Curve(x, 'Measurement Week', ('Count', 'Screenings'))\n",
    "\n",
    "timeline_histogram = hv.Histogram(timeline_curve)\n",
    "timeline_histogram\n",
    "\n",
    "tgt = timeline_histogram.relabel('VRE Screenings').opts(width=500, height=150, labelled=['y'], toolbar='disable')\n",
    "src = timeline_histogram.opts(width=800, height=150, yaxis=None, default_tools=[])\n",
    "\n",
    "RangeToolLink(src, tgt)\n",
    "\n",
    "layout = (src + tgt)\n",
    "timeline = layout.opts(opts.Layout(shared_axes=False, merge_tools=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographic Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.element.tiles.Wikipedia().opts(width=600 * 2, height=550 * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.element.tiles.CartoLight().opts(width=600 * 2, height=550 * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_networkx_graph_from_patients(patients):\n",
    "    surface_graph = SurfaceModel()\n",
    "    surface_graph.add_network_data(patient_dict=dataset, patient_subset=patients)\n",
    "    surface_graph.remove_isolated_nodes()\n",
    "    \n",
    "    return surface_graph.S_GRAPH\n",
    "\n",
    "from networkx.drawing.layout import _process_params\n",
    "\n",
    "def hospital_layout(G, building_coordinates, circular_scale=1, force_scale=0.01, center=None, dim=2):\n",
    "    # dim=2 only\n",
    "    \"\"\"Position nodes on a circle.\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : NetworkX graph or list of nodes\n",
    "        A position will be assigned to every node in G.\n",
    "    scale : number (default: 1)\n",
    "        Scale factor for positions.\n",
    "    center : array-like or None\n",
    "        Coordinate pair around which to center the layout.\n",
    "    dim : int\n",
    "        Dimension of layout.\n",
    "        If dim>2, the remaining dimensions are set to zero\n",
    "        in the returned positions.\n",
    "        If dim<2, a ValueError is raised.\n",
    "    Returns\n",
    "    -------\n",
    "    pos : dict\n",
    "        A dictionary of positions keyed by node\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If dim < 2\n",
    "    Examples\n",
    "    --------\n",
    "    >>> G = nx.path_graph(4)\n",
    "    >>> pos = nx.circular_layout(G)\n",
    "    Notes\n",
    "    -----\n",
    "    This algorithm currently only works in two dimensions and does not\n",
    "    try to minimize edge crossings.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    if dim != 2:\n",
    "        raise ValueError(\"cannot handle dimensions != 2\")\n",
    "\n",
    "    G, center = _process_params(G, center, dim)\n",
    "    \n",
    "    positions = {}\n",
    "    \n",
    "    # find room positions\n",
    "    buildings_rooms = {}\n",
    "\n",
    "    for node in G.nodes():\n",
    "        if \"type\" in G.nodes.data()[node] and G.nodes.data()[node][\"type\"] == \"Room\":\n",
    "            building_id = G.nodes.data()[node][\"building_id\"]\n",
    "            if building_id not in buildings_rooms:\n",
    "                buildings_rooms[building_id] = []\n",
    "                \n",
    "            buildings_rooms[building_id].append(node)\n",
    "        else:\n",
    "            positions[node] = np.array([826469.588389, 5.933624e06])\n",
    "    \n",
    "    for building_id, building_rooms in buildings_rooms.items():\n",
    "        \n",
    "        # find building longitude and latitude\n",
    "        try:\n",
    "            building = building_coordinates[building_id]\n",
    "            x, y = building[0], building[1]\n",
    "        except:\n",
    "            x, y = 826469.588389, 5.933624e06\n",
    "\n",
    "        room_positions = nx.circular_layout(building_rooms, center=[x, y], scale=circular_scale)\n",
    "        positions = {**positions, **room_positions}\n",
    "    \n",
    "    # find all other positions\n",
    "    positions = nx.fruchterman_reingold_layout(G, fixed=[item for sublist in list(buildings_rooms.values()) for item in sublist], pos=positions, k=force_scale)\n",
    "        \n",
    "    return positions\n",
    "\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def from_networkx(G, positions, curved_edges=0.0, nodes=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Generate a HoloViews Graph from a networkx.Graph object and\n",
    "    networkx layout function or dictionary of node positions.\n",
    "    Any keyword arguments will be passed to the layout\n",
    "    function. By default it will extract all node and edge\n",
    "    attributes from the networkx.Graph but explicit node\n",
    "    information may also be supplied. Any non-scalar attributes,\n",
    "    such as lists or dictionaries will be ignored.\n",
    "    Args:\n",
    "        G (networkx.Graph): Graph to convert to Graph element\n",
    "        positions (dict or callable): Node positions\n",
    "            Node positions defined as a dictionary mapping from\n",
    "            node id to (x, y) tuple or networkx layout function\n",
    "            which computes a positions dictionary\n",
    "        kwargs (dict): Keyword arguments for layout function\n",
    "    Returns:\n",
    "        Graph element\n",
    "    \"\"\"\n",
    "    if not isinstance(positions, dict):\n",
    "        positions = positions(G, **kwargs)\n",
    "\n",
    "    # Unpack edges\n",
    "    edges = defaultdict(list)\n",
    "    for start, end in G.edges():\n",
    "        for attr, value in sorted(G.adj[start][end].items()):\n",
    "            if isinstance(value, (list, dict)):\n",
    "                continue # Cannot handle list or dict attrs\n",
    "            edges[attr].append(value)\n",
    "\n",
    "        # Handle tuple node indexes (used in 2D grid Graphs)\n",
    "        if isinstance(start, tuple):\n",
    "            start = str(start)\n",
    "        if isinstance(end, tuple):\n",
    "            end = str(end)\n",
    "        edges['start'].append(start)\n",
    "        edges['end'].append(end)\n",
    "    edge_cols = sorted([k for k in edges if k not in ('start', 'end')\n",
    "                        and len(edges[k]) == len(edges['start'])])\n",
    "    edge_vdims = [str(col) if isinstance(col, int) else col for col in edge_cols]\n",
    "    edge_data = tuple(edges[col] for col in ['start', 'end']+edge_cols)\n",
    "\n",
    "    # Unpack user node info\n",
    "    xdim, ydim, idim = hv.Graph.node_type.kdims[:3]\n",
    "    if nodes:\n",
    "        node_columns = nodes.columns()\n",
    "        idx_dim = nodes.kdims[0].name\n",
    "        info_cols, values = zip(*((k, v) for k, v in node_columns.items() if k != idx_dim))\n",
    "        node_info = {i: vals for i, vals in zip(node_columns[idx_dim], zip(*values))}\n",
    "    else:\n",
    "        info_cols = []\n",
    "        node_info = None\n",
    "    node_columns = defaultdict(list)\n",
    "\n",
    "    # Unpack node positions\n",
    "    for idx, pos in sorted(positions.items()):\n",
    "        node = G.nodes.get(idx)\n",
    "        if node is None:\n",
    "            continue\n",
    "        x, y = pos\n",
    "        node_columns[xdim.name].append(x)\n",
    "        node_columns[ydim.name].append(y)\n",
    "        for attr, value in node.items():\n",
    "            if isinstance(value, (list, dict)):\n",
    "                continue\n",
    "            node_columns[attr].append(value)\n",
    "        for i, col in enumerate(info_cols):\n",
    "            node_columns[col].append(node_info[idx][i])\n",
    "        if isinstance(idx, tuple):\n",
    "            idx = str(idx) # Tuple node indexes handled as strings\n",
    "        node_columns[idim.name].append(idx)\n",
    "    node_cols = sorted([k for k in node_columns if k not in hv.Graph.node_type.kdims\n",
    "                        and len(node_columns[k]) == len(node_columns[xdim.name])])\n",
    "    columns = [xdim.name, ydim.name, idim.name]+node_cols+list(info_cols)\n",
    "    node_data = tuple(node_columns[col] for col in columns)\n",
    "\n",
    "    # Construct nodes\n",
    "    vdims = []\n",
    "    for col in node_cols:\n",
    "        if isinstance(col, int):\n",
    "            dim = str(col)\n",
    "        elif nodes is not None and col in nodes.vdims:\n",
    "            dim = nodes.get_dimension(col)\n",
    "        else:\n",
    "            dim = col\n",
    "        vdims.append(dim)\n",
    "    nodes = hv.Graph.node_type(node_data, vdims=vdims)\n",
    "    \n",
    "    # Construct edges\n",
    "    if curved_edges != 0:\n",
    "        # Compute edge paths\n",
    "        def bezier(start, end, control, steps=np.linspace(0, 1, 100)):\n",
    "            return (1 - steps)**2 * start + 2 * (1 - steps) * steps * control + steps**2 * end        \n",
    "        paths = []\n",
    "        for edge in G.edges():\n",
    "            sx, sy = positions[edge[0]]\n",
    "            ex, ey = positions[edge[1]]\n",
    "            \n",
    "            # get vector leading from start to end\n",
    "            vx = ex - sx\n",
    "            vy = ey - sy\n",
    "            \n",
    "            # perpendicular vector to vector above\n",
    "            perpendicular_x = -vy\n",
    "            perpendicular_y = vx\n",
    "            \n",
    "            offset = curved_edges # random.randint(-1, 1) * curved_edges #random.uniform(-curved_edges, curved_edges)\n",
    "            \n",
    "            # define bezier control point as a slight perpendicular offset from the midpoint\n",
    "            mx = (ex + sx) / 2.0 + perpendicular_x * offset\n",
    "            my = (ey + sy) / 2.0 + perpendicular_y * offset\n",
    "            \n",
    "            paths.append(np.column_stack([bezier(sx, ex, mx), bezier(sy, ey, my)]))\n",
    "            \n",
    "        graph = hv.Graph((edge_data, nodes, paths), vdims=edge_vdims)\n",
    "    else:\n",
    "        graph = hv.Graph((edge_data, nodes), vdims=edge_vdims)\n",
    "\n",
    "    # Construct graph\n",
    "    return graph\n",
    "\n",
    "def create_holoviz_graph_from_patients(patients):\n",
    "    networkx_graph = create_networkx_graph_from_patients(patients)\n",
    "    \n",
    "    networkx_graph = create_networkx_graph_from_patients(selected_patients)\n",
    "\n",
    "    positions = hospital_layout(networkx_graph, building_coordinates, circular_scale=10, force_scale=0.01)\n",
    "\n",
    "    colors = hv.Cycle('Set3').values\n",
    "    graph = from_networkx(networkx_graph, positions, curved_edges=0.15).opts(fontscale=2, width=4000, height=4000, title='Interaction network graph',\n",
    "                                                                                               node_color='type', node_size=20, node_line_width=0,\n",
    "                                                                                               edge_color='grey', edge_line_width=0.5, cmap=colors,\n",
    "                                                                                               xaxis=None, yaxis=None)\n",
    "\n",
    "    labels = hv.Labels(graph.nodes, ['x', 'y'], 'index')\n",
    "    labels.opts(text_font_size='14pt', text_color='black', bgcolor='white')\n",
    "    return graph, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holoviz Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define selectors for explorer\n",
    "# Source: https://panel.holoviz.org/reference/widgets/MultiSelect.html\n",
    "\n",
    "patient_ids = random.sample(list(dataset[\"patients\"].keys()), 1000) # too many patients\n",
    "\n",
    "selected_patients = random.sample(patient_ids, 100)\n",
    "\n",
    "graph, graph_labels = create_holoviz_graph_from_patients(selected_patients)\n",
    "\n",
    "# agent selectors\n",
    "patient_selector = pn.widgets.MultiSelect(name='Patient ID Selector', value=selected_patients, options=patient_ids, size=10)\n",
    "# device_selector = pn.widgets.MultiSelect(name='Device ID Selector', value=random.sample(top_n_patient_ids, 2), options=top_n_patient_ids, size=10)\n",
    "# employee_selector = pn.widgets.MultiSelect(name='Room ID Selector', value=random.sample(top_n_patient_ids, 2), options=top_n_patient_ids, size=10)\n",
    "\n",
    "# architecture selectors\n",
    "# building_selector = pn.widgets.MultiSelect(name='Building ID Selector', value=random.sample(top_n_patient_ids, 2), options=top_n_patient_ids, size=10)\n",
    "# floor_selector = pn.widgets.MultiSelect(name='Floor ID Selector', value=random.sample(top_n_patient_ids, 2), options=top_n_patient_ids, size=10)\n",
    "# room_selector = pn.widgets.MultiSelect(name='Room ID Selector', value=random.sample(top_n_patient_ids, 2), options=top_n_patient_ids, size=10)\n",
    "\n",
    "# Source: https://panel.holoviz.org/reference/layouts/Column.html\n",
    "data_selection_col = pn.Column(\"# Data Selection\")\n",
    "data_selection_col.append(patient_selector)\n",
    "\n",
    "# data_selection_col.append(device_selector)\n",
    "# data_selection_col.append(employee_selector)\n",
    "# data_selection_col.append(building_selector)\n",
    "# data_selection_col.append(floor_selector)\n",
    "# data_selection_col.append()\n",
    "\n",
    "# define a control tab group, source: https://panel.holoviz.org/user_guide/Components.html#Tabs\n",
    "control_tabs = pn.Tabs()\n",
    "control_tabs.append((\"Data Selection\", data_selection_col))\n",
    "\n",
    "# define a map\n",
    "map_bg = hv.element.tiles.Wikipedia()\n",
    "# map_bg = hv.element.tiles.CartoLight()\n",
    "\n",
    "# define a data plot\n",
    "building_plot = gdf.hvplot.points('coords', color='black')\n",
    "building_labels = hv.Labels({('x', 'y'): gdf[[\"coords_x\", \"coords_y\"]].to_numpy(), 'text': gdf[\"SAP Building Abbreviation 2\"].to_list()}, ['x', 'y'], 'text')#.opts(xoffset=0.5, yoffset=0.5, padding=0.2)\n",
    "# cities = gpd.read_file(gpd.datasets.get_path('naturalearth_cities'))\n",
    "# building_plot = cities.hvplot(geo=True, color='orange')\n",
    "\n",
    "# Define a dashboard grid, source: https://panel.holoviz.org/user_guide/Components.html#GridSpec\n",
    "dashboard_grid = pn.GridSpec(sizing_mode='stretch_both')\n",
    "dashboard_grid[0:9, 0] = control_tabs\n",
    "dashboard_grid[0:9, 1:5] = map_bg * building_plot * building_labels * graph * graph_labels\n",
    "dashboard_grid[10, 1:5] = timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "\n",
    "pn.panel(dashboard_grid).servable(title='Spread Explorer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # find top30 patients\n",
    "# n = 30\n",
    "# patients = set()\n",
    "# for node in networkx_graph.nodes(data=True):\n",
    "#     if \"type\" not in node[1]:\n",
    "#         continue\n",
    "        \n",
    "#     if node[1][\"type\"] == \"Patient\":\n",
    "#         patients.add(node[0])\n",
    "\n",
    "# highest_degrees = [node[0] for node in sorted(list(networkx_graph.degree), key=lambda x: x[1], reverse=True) if node[0] in patients]\n",
    "# top_n_patient_ids = highest_degrees[:n]\n",
    "# top_n_patient_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
