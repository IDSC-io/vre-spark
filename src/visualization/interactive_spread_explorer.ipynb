{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Explorer Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import networkx as nx\n",
    "import bokeh\n",
    "from holoviews import opts\n",
    "\n",
    "hv.extension('bokeh')\n",
    "\n",
    "os.chdir(\"../../\")\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "# sys.path.append('../')\n",
    "# os.chdir(\"../\")\n",
    "print(os.getcwd())\n",
    "\n",
    "import configparser\n",
    "import logging\n",
    "import pathlib\n",
    "import networkx as nx\n",
    "\n",
    "from src.features.dataloader import DataLoader\n",
    "from src.models.networkx_graph import SurfaceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s - %(levelname)s: %(message)s', level=logging.INFO,\n",
    "                    datefmt='%d.%m.%Y %H:%M:%S')\n",
    "\n",
    "logging.info(\"Initiating data_loader\") # initiate data loader\n",
    "\n",
    "\n",
    "loader = DataLoader(hdfs_pipe=False) # load all data\n",
    "dataset = loader.prepare_dataset(\n",
    "        load_patients=True,\n",
    "        load_cases=True,\n",
    "        load_stays=True,\n",
    "        load_appointments=True,\n",
    "        load_devices=True,\n",
    "        load_care_data=False, # enable if visualization works with other data\n",
    "        load_employees=True,\n",
    "        load_rooms=True,\n",
    "        load_buildings=True,\n",
    "        load_partners=False,\n",
    "        load_medications=False,\n",
    "        load_risks=False,\n",
    "        load_chop_codes=False,\n",
    "        load_surgeries=False,\n",
    "        load_icd_codes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Dashboard Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for building_id, building in dataset[\"buildings\"].items():\n",
    "    records.append(building.get_record())\n",
    "    \n",
    "waveware_buildings_df = pd.DataFrame.from_records(records)\n",
    "waveware_buildings_df.drop(columns=[\"SAP Building Abbreviation 1\"], inplace=True)\n",
    "waveware_buildings_df = waveware_buildings_df.drop_duplicates(subset=[\"WW Building ID\"])\n",
    "waveware_buildings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show building data we have directly from Waveware\n",
    "# base_folder = \"./data/raw/model_data/\"\n",
    "# waveware_buildings_df = pd.read_csv(base_folder + \"Waveware_Auszug Gebaeudeinformation Stand 03.12.2020.csv\", encoding=\"ISO-8859-1\", dtype=str)\n",
    "\n",
    "# waveware_buildings_df = waveware_buildings_df.drop([\"Standort\", \"Parzellennummer\", \"Zonenplan\", \"Denkmalpflege\", \"Anlage-ID\", \"Bemerkung\", \"Eigentümer (SAP)\", \"Vermietung (SAP)\", \"Portfolio (SAP)\", \"Baujahr\", \"Gebäudetyp\", \"GVB-Nummer\", \"Amtlicher Wert\", \"Gebäudeversicherungswert\", \"Gebäudezustand\", \"Technologiestand HLKSE\", \"Techn. Ausb.standard\", \"Zustand Technik\", \"Klimatisierung\", \"Aufzug\", \"Gebäudezustand Bem.\", \"Status\"], axis=1)\n",
    "# waveware_buildings_df.columns = [\"Waveware Building Full ID\", \"Building Code\", \"Waveware Building ID\", \"Building abbreviation\", \"Building Common Name\", \"Street\", \"Zip Code\", \"Location\", \"SAP-Anlage Nr.\"]\n",
    "# waveware_buildings_df.drop([\"Zip Code\", \"Location\",\"SAP-Anlage Nr.\", \"Building Code\"], axis=1, inplace=True)\n",
    "# waveware_buildings_df = waveware_buildings_df[waveware_buildings_df[\"Building Common Name\"] != \"Grundstück Inselareal\"]\n",
    "\n",
    "# waveware_buildings_df = waveware_buildings_df[~pd.isna(waveware_buildings_df[\"Building abbreviation\"])]\n",
    "# waveware_buildings_df.sort_values(by=[\"Building abbreviation\"], inplace=True)\n",
    "# # waveware_buildings_df.set_index(\"Waveware Building ID\", inplace=True)\n",
    "# waveware_buildings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # augment building data with building coordinates\n",
    "# # TODO: Move this to dataset improvement\n",
    "# import requests\n",
    "\n",
    "# def get_long_lat(street_string):\n",
    "#     response = requests.get(f\"https://nominatim.openstreetmap.org/search?q={street_string.replace(' ', '+')}+Bern&format=json\")\n",
    "#     types = []\n",
    "#     for loc in response.json():\n",
    "#         types.append(loc[\"type\"] + \": \" + loc[\"display_name\"][:15])\n",
    "#         if loc[\"type\"] in [\"hospital\", \"childcare\", \"clinic\"]:\n",
    "#             id_string = loc[\"type\"] + \": \" + loc[\"display_name\"][:15]\n",
    "#             long_lat = (loc[\"lon\"], loc[\"lat\"])\n",
    "#             return pd.Series({'Type': id_string, 'Long/Lat': long_lat})\n",
    "        \n",
    "#     id_string = response.json()[0][\"type\"] + \": \" + response.json()[0][\"display_name\"][:15]\n",
    "#     long_lat = (response.json()[0][\"lon\"], response.json()[0][\"lat\"])\n",
    "#     return pd.Series({'Type': id_string, 'Long/Lat': long_lat})\n",
    "\n",
    "\n",
    "# waveware_buildings_coords_df = pd.concat([waveware_buildings_df, waveware_buildings_df[\"Street\"].apply(lambda s: get_long_lat(s))], axis=1)\n",
    "# waveware_buildings_coords_df[\"Longitude\"] = waveware_buildings_coords_df[\"Long/Lat\"].apply(lambda ll: float(ll[0]))\n",
    "# waveware_buildings_coords_df[\"Latitude\"] = waveware_buildings_coords_df[\"Long/Lat\"].apply(lambda ll: float(ll[1]))\n",
    "# waveware_buildings_coords_df.drop([\"Long/Lat\"], axis=1, inplace=True)\n",
    "# waveware_buildings_coords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waveware_buildings_coords_df[\"Waveware Building ID\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    waveware_buildings_df, geometry=gpd.points_from_xy(waveware_buildings_df.Longitude, waveware_buildings_df.Latitude))\n",
    "gdf.set_crs(epsg=4326, inplace=True)\n",
    "gdf = gdf.to_crs(epsg=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['coords'] = gdf['geometry'].apply(lambda x: x.representative_point().coords[:])\n",
    "gdf['coords_x'], gdf['coords_y'] = [coords[0][0] for coords in gdf['coords']], [coords[0][1] for coords in gdf['coords']]\n",
    "\n",
    "building_coordinates = list(gdf.apply(lambda row: [row[\"WW Building ID\"], (row[\"coords_x\"], row[\"coords_y\"])], axis=1))\n",
    "building_coordinates = {item[0]:item[1] for item in building_coordinates}\n",
    "# for row in gdf.iteritems():\n",
    "#     building_coordinates[row[\"WW Building ID\"]] = (row[\"coords_x\"], row[\"coords_y\"])\n",
    "\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Dashboard Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "import random\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "import xarray as xr\n",
    "import hvplot.pandas  # noqa\n",
    "import hvplot.xarray  # noqa\n",
    "hv.extension('bokeh')\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side Pane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"buildings\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(dataset[\"patients\"].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import param\n",
    "\n",
    "#build timeline\n",
    "from holoviews.plotting.links import RangeToolLink\n",
    "\n",
    "base_folder = \"./data/interim/model_data/\"\n",
    "vre_screening_df = pd.read_csv(base_folder + \"VRE_SCREENING_DATA.csv\", encoding=\"ISO-8859-1\", parse_dates=[\"Birth Date\", \"Measurement Date\"], dtype=\"str\")\n",
    "\n",
    "min_date = vre_screening_df[\"Measurement Date\"].min()\n",
    "max_date = vre_screening_df[\"Measurement Date\"].max()\n",
    "\n",
    "# do some preprocessing\n",
    "vre_screening_df[\"Patient ID\"] = vre_screening_df[\"Patient ID\"].apply(lambda patient_id: str(patient_id).zfill(11))\n",
    "df = vre_screening_df\n",
    "vre_screening_df[\"Measurement Date d64\"] = vre_screening_df[\"Measurement Date\"].astype(\"datetime64\")\n",
    "df = vre_screening_df.loc[vre_screening_df[\"Result\"] != \"nn\"]\n",
    "df[\"Year\"] = df[\"Measurement Date d64\"].dt.year\n",
    "df[\"Week\"] = df[\"Measurement Date d64\"].dt.week\n",
    "x = pd.DataFrame(df[[\"Measurement Date d64\"]].groupby([df[\"Year\"], df[\"Week\"]]).count())\n",
    "x.columns = [\"Count\"]\n",
    "x = x.reset_index()\n",
    "x[\"Week\"] = x[\"Week\"].astype(\"int32\").astype(\"str\")\n",
    "x[\"Year\"] = x[\"Year\"].astype(\"int32\").astype(\"str\")\n",
    "x[\"Year/Week\"] = x[\"Year\"] + \"/\" + x[\"Week\"] + \"1\"\n",
    "x[\"Measurement Week\"] = x[\"Year/Week\"].apply(lambda x: pd.to_datetime(x, format='%Y/%W%w'))\n",
    "x[[\"Measurement Week\", \"Count\"]]\n",
    "\n",
    "timeline_curve = hv.Curve(x, 'Measurement Week', ('Count', 'Screenings'))\n",
    "timeline_histogram = hv.Histogram(timeline_curve)\n",
    "\n",
    "RangeSelector = hv.streams.Stream.define('RangeSelector', xmin=param.Date(default=None), xmax=param.Date(default=None))\n",
    "\n",
    "my_range = RangeSelector(xmin=dt.datetime(2019, 6, 8), xmax=dt.datetime(2019, 8, 3))\n",
    "\n",
    "def gen_target(xmin, xmax):\n",
    "    if xmin is not None and xmax is not None:\n",
    "        return hv.Histogram(timeline_curve).opts(xlim=(xmin, xmax), width=500, height=150, labelled=['y'], toolbar='disable')\n",
    "    else:\n",
    "        return hv.Histogram(timeline_curve).opts(width=500, height=150, labelled=['y'], toolbar='disable')\n",
    "\n",
    "target_dmap = hv.DynamicMap(gen_target, streams=[my_range])\n",
    "\n",
    "def subscribe(x_range=(0,0), y_range=(0,0)):\n",
    "    print('x_range: ', x_range)\n",
    "\n",
    "range_xy_stream = hv.streams.RangeXY(source=target_dmap)\n",
    "range_xy_stream.add_subscriber(subscribe)\n",
    "\n",
    "source = timeline_histogram.opts(width=800, height=150, yaxis=None, default_tools=[])\n",
    "\n",
    "def gen_source(x_range=(0,0), y_range=(0,0)):\n",
    "    return source\n",
    "\n",
    "source_dmap = hv.DynamicMap(gen_source, streams=[range_xy_stream])\n",
    "\n",
    "rtlink = hv.plotting.links.RangeToolLink(source_dmap, target_dmap)\n",
    "layout = (source_dmap + target_dmap).cols(2)\n",
    "timeline = layout.opts(opts.Layout(shared_axes=False, merge_tools=False))\n",
    "timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range query AVL Tree\n",
    "\n",
    "#import random, math\n",
    "\n",
    "outputdebug = False\n",
    "\n",
    "def debug(msg):\n",
    "    if outputdebug:\n",
    "        print(msg)\n",
    "\n",
    "class Node():\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.left = None \n",
    "        self.right = None \n",
    "        \n",
    "    def __str__(self):\n",
    "        left_key = str(self.left.node.key) if self.left is not None else \"None\"\n",
    "        right_key = str(self.right.node.key) if self.right is not None else \"None\"\n",
    "        print(f\"{self.key}, {left_key}, {right_key}\")\n",
    "\n",
    "class AVLTree():\n",
    "    def __init__(self, *args):\n",
    "        self.node = None \n",
    "        self.height = -1  \n",
    "        self.balance = 0; \n",
    "        \n",
    "        if len(args) == 1: \n",
    "            for i in args[0]: \n",
    "                self.insert(i)\n",
    "                \n",
    "    def height(self):\n",
    "        if self.node: \n",
    "            return self.node.height \n",
    "        else: \n",
    "            return 0 \n",
    "    \n",
    "    def is_leaf(self):\n",
    "        return (self.height == 0) \n",
    "    \n",
    "    def insert(self, key):\n",
    "        tree = self.node\n",
    "        \n",
    "        newnode = Node(key)\n",
    "        \n",
    "        if tree == None:\n",
    "            self.node = newnode \n",
    "            self.node.left = AVLTree() \n",
    "            self.node.right = AVLTree()\n",
    "            debug(\"Inserted key [\" + str(key) + \"]\")\n",
    "        \n",
    "        elif key < tree.key: \n",
    "            self.node.left.insert(key)\n",
    "            \n",
    "        elif key > tree.key: \n",
    "            self.node.right.insert(key)\n",
    "        \n",
    "        else: \n",
    "            debug(\"Key [\" + str(key) + \"] already in tree.\")\n",
    "            \n",
    "        self.rebalance() \n",
    "        \n",
    "    def rebalance(self):\n",
    "        \"\"\" \n",
    "        Rebalance a particular (sub)tree\n",
    "        \"\"\" \n",
    "        # key inserted. Let's check if we're balanced\n",
    "        self.update_heights(False)\n",
    "        self.update_balances(False)\n",
    "        while self.balance < -1 or self.balance > 1: \n",
    "            if self.balance > 1:\n",
    "                if self.node.left.balance < 0:  \n",
    "                    self.node.left.lrotate() # we're in case II\n",
    "                    self.update_heights()\n",
    "                    self.update_balances()\n",
    "                self.rrotate()\n",
    "                self.update_heights()\n",
    "                self.update_balances()\n",
    "                \n",
    "            if self.balance < -1:\n",
    "                if self.node.right.balance > 0:  \n",
    "                    self.node.right.rrotate() # we're in case III\n",
    "                    self.update_heights()\n",
    "                    self.update_balances()\n",
    "                self.lrotate()\n",
    "                self.update_heights()\n",
    "                self.update_balances()\n",
    "\n",
    "\n",
    "            \n",
    "    def rrotate(self):\n",
    "        # Rotate left pivoting on self\n",
    "        debug('Rotating ' + str(self.node.key) + ' right') \n",
    "        A = self.node \n",
    "        B = self.node.left.node \n",
    "        T = B.right.node \n",
    "        \n",
    "        self.node = B \n",
    "        B.right.node = A \n",
    "        A.left.node = T \n",
    "\n",
    "    \n",
    "    def lrotate(self):\n",
    "        # Rotate left pivoting on self\n",
    "        debug('Rotating ' + str(self.node.key) + ' left') \n",
    "        A = self.node \n",
    "        B = self.node.right.node \n",
    "        T = B.left.node \n",
    "        \n",
    "        self.node = B \n",
    "        B.left.node = A \n",
    "        A.right.node = T \n",
    "        \n",
    "            \n",
    "    def update_heights(self, recurse=True):\n",
    "        if not self.node == None: \n",
    "            if recurse: \n",
    "                if self.node.left != None: \n",
    "                    self.node.left.update_heights()\n",
    "                if self.node.right != None:\n",
    "                    self.node.right.update_heights()\n",
    "            \n",
    "            self.height = max(self.node.left.height,\n",
    "                              self.node.right.height) + 1 \n",
    "        else: \n",
    "            self.height = -1 \n",
    "            \n",
    "    def update_balances(self, recurse=True):\n",
    "        if not self.node == None: \n",
    "            if recurse: \n",
    "                if self.node.left != None: \n",
    "                    self.node.left.update_balances()\n",
    "                if self.node.right != None:\n",
    "                    self.node.right.update_balances()\n",
    "\n",
    "            self.balance = self.node.left.height - self.node.right.height \n",
    "        else: \n",
    "            self.balance = 0\n",
    "\n",
    "    def delete(self, key):\n",
    "        # debug(\"Trying to delete at node: \" + str(self.node.key))\n",
    "        if self.node != None: \n",
    "            if self.node.key == key: \n",
    "                debug(\"Deleting ... \" + str(key))  \n",
    "                if self.node.left.node == None and self.node.right.node == None:\n",
    "                    self.node = None # leaves can be killed at will \n",
    "                # if only one subtree, take that \n",
    "                elif self.node.left.node == None: \n",
    "                    self.node = self.node.right.node\n",
    "                elif self.node.right.node == None: \n",
    "                    self.node = self.node.left.node\n",
    "                \n",
    "                # worst-case: both children present. Find logical successor\n",
    "                else:  \n",
    "                    replacement = self.logical_successor(self.node)\n",
    "                    if replacement != None: # sanity check \n",
    "                        debug(\"Found replacement for \" + str(key) + \" -> \" + str(replacement.key))  \n",
    "                        self.node.key = replacement.key \n",
    "                        \n",
    "                        # replaced. Now delete the key from right child \n",
    "                        self.node.right.delete(replacement.key)\n",
    "                    \n",
    "                self.rebalance()\n",
    "                return  \n",
    "            elif key < self.node.key: \n",
    "                self.node.left.delete(key)  \n",
    "            elif key > self.node.key: \n",
    "                self.node.right.delete(key)\n",
    "                        \n",
    "            self.rebalance()\n",
    "        else: \n",
    "            return \n",
    "\n",
    "    def logical_predecessor(self, node):\n",
    "        \"\"\" \n",
    "        Find the biggest valued node in LEFT child\n",
    "        \"\"\" \n",
    "        node = node.left.node \n",
    "        if node != None: \n",
    "            while node.right != None:\n",
    "                if node.right.node == None: \n",
    "                    return node \n",
    "                else: \n",
    "                    node = node.right.node  \n",
    "        return node \n",
    "    \n",
    "    def logical_successor(self, node):\n",
    "        \"\"\" \n",
    "        Find the smallest valued node in RIGHT child\n",
    "        \"\"\" \n",
    "        node = node.right.node  \n",
    "        if node != None: # just a sanity check  \n",
    "            \n",
    "            while node.left != None:\n",
    "                debug(\"LS: traversing: \" + str(node.key))\n",
    "                if node.left.node == None: \n",
    "                    return node \n",
    "                else: \n",
    "                    node = node.left.node  \n",
    "        return node \n",
    "\n",
    "    def check_balanced(self):\n",
    "        if self == None or self.node == None: \n",
    "            return True\n",
    "        \n",
    "        # We always need to make sure we are balanced \n",
    "        self.update_heights()\n",
    "        self.update_balances()\n",
    "        return ((abs(self.balance) < 2) and self.node.left.check_balanced() and self.node.right.check_balanced())  \n",
    "        \n",
    "    def inorder_traverse(self):\n",
    "        if self.node == None:\n",
    "            return [] \n",
    "        \n",
    "        inlist = [] \n",
    "        l = self.node.left.inorder_traverse()\n",
    "        for i in l: \n",
    "            inlist.append(i) \n",
    "\n",
    "        inlist.append(self.node.key)\n",
    "\n",
    "        l = self.node.right.inorder_traverse()\n",
    "        for i in l: \n",
    "            inlist.append(i) \n",
    "    \n",
    "        return inlist \n",
    "\n",
    "    def display(self, level=0, pref=''):\n",
    "        \"\"\"\n",
    "        Display the whole tree. Uses recursive def.\n",
    "        TODO: create a better display using breadth-first search\n",
    "        \"\"\"        \n",
    "        self.update_heights()  # Must update heights before balances \n",
    "        self.update_balances()\n",
    "        if(self.node != None): \n",
    "            print('-' * level * 2, pref, self.node.key, \"[\" + str(self.height) + \":\" + str(self.balance) + \"]\", 'L' if self.is_leaf() else ' ')\n",
    "            if self.node.left != None: \n",
    "                self.node.left.display(level + 1, '<')\n",
    "            if self.node.left != None:\n",
    "                self.node.right.display(level + 1, '>')\n",
    "                \n",
    "                \n",
    "    def range_query(self, a, b):\n",
    "        return self._traverse_range(self.node, a, b)\n",
    "\n",
    "    def _traverse_range(self, subtree, a, b, cumresult=None):\n",
    "        if subtree is None:\n",
    "            return\n",
    "\n",
    "        # Cumulative variable.\n",
    "        if cumresult is None:\n",
    "            cumresult = []\n",
    "\n",
    "        # Traverse LEFT subtree if it is possible to find values in required range there.\n",
    "        if subtree.key > a:\n",
    "            self._traverse_range(subtree.left.node, a, b, cumresult)\n",
    "\n",
    "        # Push VALUE if it is in our range.\n",
    "        if a <= subtree.key < b:  # Change to strict \"< b\" to act like python's range\n",
    "            cumresult.append(subtree.key)\n",
    "\n",
    "        # Traverse RIGHT subtree if it is possible to find values in required range there.\n",
    "        if subtree.key < b:\n",
    "            self._traverse_range(subtree.right.node, a, b, cumresult)\n",
    "\n",
    "        return cumresult\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "a = AVLTree()\n",
    "print(\"----- Inserting -------\")\n",
    "inlist = [5, 2, 12, -4, 3, 21, 19, 25]\n",
    "#inlist = [7, 5, 2, 6, 3, 4, 1, 8, 9, 0]\n",
    "for i in inlist: \n",
    "    a.insert(i)\n",
    "\n",
    "a.display()\n",
    "\n",
    "print(\"----- Deleting -------\")\n",
    "a.delete(3)\n",
    "a.delete(4)\n",
    "# a.delete(5) \n",
    "a.display()\n",
    "\n",
    "print(\"Input            :\", inlist)\n",
    "print(\"deleting ...       \", 3)\n",
    "print(\"deleting ...       \", 4)\n",
    "print(\"Inorder traversal:\", a.inorder_traverse())\n",
    "print(a.check_balanced())\n",
    "\n",
    "print(a.range_query(5, 20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographic Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hv.element.tiles.Wikipedia().opts(width=600 * 2, height=550 * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hv.element.tiles.CartoLight().opts(width=600 * 2, height=550 * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_networkx_graph_from_patients(patients):\n",
    "    surface_graph = SurfaceModel()\n",
    "    surface_graph.add_network_data(patient_dict=dataset, patient_subset=patients)\n",
    "    surface_graph.remove_isolated_nodes()\n",
    "    \n",
    "    return surface_graph.S_GRAPH\n",
    "\n",
    "from networkx.drawing.layout import _process_params\n",
    "\n",
    "def hospital_layout(G, building_coordinates, circular_scale=1, force_scale=0.01, center=None, dim=2):\n",
    "    # dim=2 only\n",
    "    \"\"\"Position nodes on a circle.\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : NetworkX graph or list of nodes\n",
    "        A position will be assigned to every node in G.\n",
    "    scale : number (default: 1)\n",
    "        Scale factor for positions.\n",
    "    center : array-like or None\n",
    "        Coordinate pair around which to center the layout.\n",
    "    dim : int\n",
    "        Dimension of layout.\n",
    "        If dim>2, the remaining dimensions are set to zero\n",
    "        in the returned positions.\n",
    "        If dim<2, a ValueError is raised.\n",
    "    Returns\n",
    "    -------\n",
    "    pos : dict\n",
    "        A dictionary of positions keyed by node\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If dim < 2\n",
    "    Examples\n",
    "    --------\n",
    "    >>> G = nx.path_graph(4)\n",
    "    >>> pos = nx.circular_layout(G)\n",
    "    Notes\n",
    "    -----\n",
    "    This algorithm currently only works in two dimensions and does not\n",
    "    try to minimize edge crossings.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    if dim != 2:\n",
    "        raise ValueError(\"cannot handle dimensions != 2\")\n",
    "\n",
    "    G, center = _process_params(G, center, dim)\n",
    "    \n",
    "    positions = {}\n",
    "    \n",
    "    # find room positions\n",
    "    buildings_rooms = {}\n",
    "\n",
    "    for node in G.nodes():\n",
    "        if \"type\" in G.nodes.data()[node] and G.nodes.data()[node][\"type\"] == \"Room\":\n",
    "            building_id = G.nodes.data()[node][\"building_id\"]\n",
    "            if building_id not in buildings_rooms:\n",
    "                buildings_rooms[building_id] = []\n",
    "                \n",
    "            buildings_rooms[building_id].append(node)\n",
    "        else:\n",
    "            positions[node] = np.array([826469.588389, 5.933624e06])\n",
    "    \n",
    "    for building_id, building_rooms in buildings_rooms.items():\n",
    "        \n",
    "        # find building longitude and latitude\n",
    "        try:\n",
    "            building = building_coordinates[building_id]\n",
    "            x, y = building[0], building[1]\n",
    "        except:\n",
    "            x, y = 826469.588389, 5.933624e06\n",
    "\n",
    "        room_positions = nx.circular_layout(building_rooms, center=[x, y], scale=circular_scale)\n",
    "        positions = {**positions, **room_positions}\n",
    "    \n",
    "    # find all other positions\n",
    "    positions = nx.fruchterman_reingold_layout(G, fixed=[item for sublist in list(buildings_rooms.values()) for item in sublist], pos=positions, k=force_scale)\n",
    "        \n",
    "    return positions\n",
    "\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def from_networkx(G, positions, curved_edges=0.0, nodes=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Generate a HoloViews Graph from a networkx.Graph object and\n",
    "    networkx layout function or dictionary of node positions.\n",
    "    Any keyword arguments will be passed to the layout\n",
    "    function. By default it will extract all node and edge\n",
    "    attributes from the networkx.Graph but explicit node\n",
    "    information may also be supplied. Any non-scalar attributes,\n",
    "    such as lists or dictionaries will be ignored.\n",
    "    Args:\n",
    "        G (networkx.Graph): Graph to convert to Graph element\n",
    "        positions (dict or callable): Node positions\n",
    "            Node positions defined as a dictionary mapping from\n",
    "            node id to (x, y) tuple or networkx layout function\n",
    "            which computes a positions dictionary\n",
    "        kwargs (dict): Keyword arguments for layout function\n",
    "    Returns:\n",
    "        Graph element\n",
    "    \"\"\"\n",
    "    if not isinstance(positions, dict):\n",
    "        positions = positions(G, **kwargs)\n",
    "\n",
    "    # Unpack edges\n",
    "    edges = defaultdict(list)\n",
    "    for start, end in G.edges():\n",
    "        for attr, value in sorted(G.adj[start][end].items()):\n",
    "            if isinstance(value, (list, dict)):\n",
    "                continue # Cannot handle list or dict attrs\n",
    "            edges[attr].append(value)\n",
    "\n",
    "        # Handle tuple node indexes (used in 2D grid Graphs)\n",
    "        if isinstance(start, tuple):\n",
    "            start = str(start)\n",
    "        if isinstance(end, tuple):\n",
    "            end = str(end)\n",
    "        edges['start'].append(start)\n",
    "        edges['end'].append(end)\n",
    "    edge_cols = sorted([k for k in edges if k not in ('start', 'end')\n",
    "                        and len(edges[k]) == len(edges['start'])])\n",
    "    edge_vdims = [str(col) if isinstance(col, int) else col for col in edge_cols]\n",
    "    edge_data = tuple(edges[col] for col in ['start', 'end']+edge_cols)\n",
    "\n",
    "    # Unpack user node info\n",
    "    xdim, ydim, idim = hv.Graph.node_type.kdims[:3]\n",
    "    if nodes:\n",
    "        node_columns = nodes.columns()\n",
    "        idx_dim = nodes.kdims[0].name\n",
    "        info_cols, values = zip(*((k, v) for k, v in node_columns.items() if k != idx_dim))\n",
    "        node_info = {i: vals for i, vals in zip(node_columns[idx_dim], zip(*values))}\n",
    "    else:\n",
    "        info_cols = []\n",
    "        node_info = None\n",
    "    node_columns = defaultdict(list)\n",
    "\n",
    "    # Unpack node positions\n",
    "    for idx, pos in sorted(positions.items()):\n",
    "        node = G.nodes.get(idx)\n",
    "        if node is None:\n",
    "            continue\n",
    "        x, y = pos\n",
    "        node_columns[xdim.name].append(x)\n",
    "        node_columns[ydim.name].append(y)\n",
    "        for attr, value in node.items():\n",
    "            if isinstance(value, (list, dict)):\n",
    "                continue\n",
    "            node_columns[attr].append(value)\n",
    "        for i, col in enumerate(info_cols):\n",
    "            node_columns[col].append(node_info[idx][i])\n",
    "        if isinstance(idx, tuple):\n",
    "            idx = str(idx) # Tuple node indexes handled as strings\n",
    "        node_columns[idim.name].append(idx)\n",
    "    node_cols = sorted([k for k in node_columns if k not in hv.Graph.node_type.kdims\n",
    "                        and len(node_columns[k]) == len(node_columns[xdim.name])])\n",
    "    columns = [xdim.name, ydim.name, idim.name]+node_cols+list(info_cols)\n",
    "    node_data = tuple(node_columns[col] for col in columns)\n",
    "\n",
    "    # Construct nodes\n",
    "    vdims = []\n",
    "    for col in node_cols:\n",
    "        if isinstance(col, int):\n",
    "            dim = str(col)\n",
    "        elif nodes is not None and col in nodes.vdims:\n",
    "            dim = nodes.get_dimension(col)\n",
    "        else:\n",
    "            dim = col\n",
    "        vdims.append(dim)\n",
    "    nodes = hv.Graph.node_type(node_data, vdims=vdims)\n",
    "    \n",
    "    # Construct edges\n",
    "    if curved_edges != 0:\n",
    "        # Compute edge paths\n",
    "        def bezier(start, end, control, steps=np.linspace(0, 1, 100)):\n",
    "            return (1 - steps)**2 * start + 2 * (1 - steps) * steps * control + steps**2 * end        \n",
    "        paths = []\n",
    "        for edge in G.edges():\n",
    "            sx, sy = positions[edge[0]]\n",
    "            ex, ey = positions[edge[1]]\n",
    "            \n",
    "            # get vector leading from start to end\n",
    "            vx = ex - sx\n",
    "            vy = ey - sy\n",
    "            \n",
    "            # perpendicular vector to vector above\n",
    "            perpendicular_x = -vy\n",
    "            perpendicular_y = vx\n",
    "            \n",
    "            offset = curved_edges # random.randint(-1, 1) * curved_edges #random.uniform(-curved_edges, curved_edges)\n",
    "            \n",
    "            # define bezier control point as a slight perpendicular offset from the midpoint\n",
    "            mx = (ex + sx) / 2.0 + perpendicular_x * offset\n",
    "            my = (ey + sy) / 2.0 + perpendicular_y * offset\n",
    "            \n",
    "            paths.append(np.column_stack([bezier(sx, ex, mx), bezier(sy, ey, my)]))\n",
    "            \n",
    "        graph = hv.Graph((edge_data, nodes, paths), vdims=edge_vdims)\n",
    "    else:\n",
    "        graph = hv.Graph((edge_data, nodes), vdims=edge_vdims)\n",
    "\n",
    "    # Construct graph\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holoviz Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids = random.sample(list(dataset[\"patients\"].keys()), 300) # too many patients\n",
    "\n",
    "selected_patients = random.sample(patient_ids, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define selectors for explorer\n",
    "# Source: https://panel.holoviz.org/reference/widgets/MultiSelect.html\n",
    "# agent selectors\n",
    "patient_selector = pn.widgets.MultiSelect(name='Patient ID Selector', value=selected_patients, options=patient_ids, size=10)\n",
    "# device_selector = pn.widgets.MultiSelect(name='Device ID Selector', value=random.sample(top_n_patient_ids, 2), options=top_n_patient_ids, size=10)\n",
    "# employee_selector = pn.widgets.MultiSelect(name='Room ID Selector', value=random.sample(top_n_patient_ids, 2), options=top_n_patient_ids, size=10)\n",
    "\n",
    "# architecture selectors\n",
    "# building_selector = pn.widgets.MultiSelect(name='Building ID Selector', value=random.sample(top_n_patient_ids, 2), options=top_n_patient_ids, size=10)\n",
    "# floor_selector = pn.widgets.MultiSelect(name='Floor ID Selector', value=random.sample(top_n_patient_ids, 2), options=top_n_patient_ids, size=10)\n",
    "# room_selector = pn.widgets.MultiSelect(name='Room ID Selector', value=random.sample(top_n_patient_ids, 2), options=top_n_patient_ids, size=10)\n",
    "\n",
    "# Source: https://panel.holoviz.org/reference/layouts/Column.html\n",
    "data_selection_col = pn.Column(\"# Data Selection\")\n",
    "data_selection_col.append(patient_selector)\n",
    "\n",
    "# data_selection_col.append(device_selector)\n",
    "# data_selection_col.append(employee_selector)\n",
    "# data_selection_col.append(building_selector)\n",
    "# data_selection_col.append(floor_selector)\n",
    "\n",
    "# define a control tab group, source: https://panel.holoviz.org/user_guide/Components.html#Tabs\n",
    "control_tabs = pn.Tabs()\n",
    "control_tabs.append((\"Data Selection\", data_selection_col))\n",
    "\n",
    "# define a map\n",
    "# map_bg = hv.element.tiles.Wikipedia()\n",
    "map_bg = hv.element.tiles.CartoLight()\n",
    "\n",
    "# define a data plot\n",
    "building_labels = hv.Labels({('x', 'y'): gdf[[\"coords_x\", \"coords_y\"]].to_numpy(), 'text': gdf[\"SAP Building Abbreviation 2\"].to_list()}, ['x', 'y'], 'text')\n",
    "\n",
    "\n",
    "@pn.depends(selected_patients=patient_selector.param.value)\n",
    "def load_mapview(selected_patients):\n",
    "    print(\"Recreating the graph...\")\n",
    "    networkx_graph = create_networkx_graph_from_patients(selected_patients)\n",
    "    positions = hospital_layout(networkx_graph, building_coordinates, circular_scale=10, force_scale=0.01)\n",
    "\n",
    "    colors = hv.Cycle('Set3').values\n",
    "    graph = from_networkx(networkx_graph, positions, curved_edges=0.15).opts(fontscale=2, width=1200, height=800,\n",
    "                                                                                               node_color='type', node_size=20, node_line_width=0,\n",
    "                                                                                               edge_color='grey', edge_line_width=0.5, cmap=colors,\n",
    "                                                                                               xaxis=None, yaxis=None)\n",
    "    labels = hv.Labels(graph.nodes, ['x', 'y'], 'index')\n",
    "    labels.opts(text_font_size='14pt', text_color='black', bgcolor='white')\n",
    "    print(\"...Done.\")\n",
    "    return map_bg * building_labels * graph # * labels\n",
    "\n",
    "mapview_dmap = hv.DynamicMap(load_mapview)\n",
    "\n",
    "# Define a dashboard grid, source: https://panel.holoviz.org/user_guide/Components.html#GridSpec\n",
    "dashboard_grid = pn.GridSpec(sizing_mode='stretch_both')\n",
    "dashboard_grid[0:9, 0] = control_tabs\n",
    "dashboard_grid[0:9, 1:5] = mapview_dmap\n",
    "dashboard_grid[10, 1:5] = timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "\n",
    "pn.panel(dashboard_grid).servable(title='Spread Explorer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find top30 patients\n",
    "# n = 30\n",
    "# patients = set()\n",
    "# for node in networkx_graph.nodes(data=True):\n",
    "#     if \"type\" not in node[1]:\n",
    "#         continue\n",
    "        \n",
    "#     if node[1][\"type\"] == \"Patient\":\n",
    "#         patients.add(node[0])\n",
    "\n",
    "# highest_degrees = [node[0] for node in sorted(list(networkx_graph.degree), key=lambda x: x[1], reverse=True) if node[0] in patients]\n",
    "# top_n_patient_ids = highest_degrees[:n]\n",
    "# top_n_patient_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "import holoviews.plotting.bokeh\n",
    "\n",
    "points = hv.Points(np.random.randn(1000,2 )).opts(tools=['box_select', 'lasso_select'])\n",
    "selection = hv.streams.Selection1D(source=points)\n",
    "\n",
    "def selected_info(index):\n",
    "    arr = points.array()[index]\n",
    "    if index:\n",
    "        label = 'Mean x, y: %.3f, %.3f' % tuple(arr.mean(axis=0))\n",
    "    else:\n",
    "        label = 'No selection'\n",
    "    return points.clone(arr, label=label).opts(color='red')\n",
    "\n",
    "layout = points + hv.DynamicMap(selected_info, streams=[selection])\n",
    "layout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
